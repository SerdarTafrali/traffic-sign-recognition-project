# -*- coding: utf-8 -*-
"""234329035_SERDAR_TAFRALI_YAPAY_SINIR_AGLARI_MIDTERM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17fjMcYcfUrbvqbJjSC_zMhDQCaYVWn5J

# MLP ve RBF Ağları Kullanarak Sınıflandırma Uygulaması

Bu proje, **Çok Katmanlı Algılayıcılar (MLP)** ve **Radial Basis Function (RBF)** ağlarını kullanarak bir sınıflandırma uygulaması yapmayı hedeflemektedir. Adım adım veri ön işleme, model eğitimi, hiperparametre optimizasyonu ve performans değerlendirmesi yapılacaktır.

## İçerik

### 1. Gerekli Kütüphanelerin Yüklenmesi
- `pandas`, `numpy` (veri işleme)
- `sklearn`, `keras` (model oluşturma, veri ayırma, performans metrikleri)
- `matplotlib` ve `seaborn` (görselleştirme)

### 2. Veri Seti Yükleme ve Ön İşleme
1. **Veri Yükleme**
2. **Eksik Değerlerin İşlenmesi**
   - Eğer veri setinde eksik değerler varsa, uygun yöntemlerle doldurulmalıdır.
3. **Veri Setini Eğitim ve Test Olarak Ayırma**
   - Veriyi %80 eğitim, %20 test olarak ikiye ayırın.
   - `sklearn.model_selection.train_test_split` fonksiyonunu kullanın.
4. **Özellik Ölçekleme (Feature Scaling)**
   - Verileri MLP ve RBF için uygun hale getirmek adına standartlaştırın (örn. `StandardScaler` veya `MinMaxScaler` kullanarak).

### 3. Model Eğitimi ve Hiperparametre Denemeleri
1. **MLP Modeli**
   - `sklearn.neural_network.MLPClassifier` kullanarak bir MLP modeli oluşturun.
   - Hiperparametre denemeleri için farklı katman sayıları, nöron sayıları ve aktivasyon fonksiyonlarını test edin (örn. `hidden_layer_sizes`, `activation` ve `learning_rate` gibi parametreler).
2. **RBF Modeli**
   - `sklearn` kütüphanesinde doğrudan RBF modeli bulunmadığından, `Keras` kütüphanesi kullanın.
   - Alternatif olarak, `rbfnetwork` gibi özel kütüphaneler veya Python’da yazılmış RBF fonksiyonları kullanılabilir.

### 4. Performans Ölçümleri
1. **Confusion Matrix**
   - Her iki model için tahminleri değerlendirerek karışıklık matrisini (`confusion_matrix`) oluşturun.
   - `seaborn` kullanarak karışıklık matrisini görselleştirin.
2. **Performans Metrikleri**
   - Her iki model için `accuracy`, `precision`, `recall`, ve `F1-score` gibi metrikleri hesaplayın (`sklearn.metrics.classification_report` fonksiyonunu kullanarak).

### 5. Hiperparametre Denemeleri ve Sonuçları Karşılaştırma
1. **Hiperparametre Denemeleri**
   - MLP ve RBF modelleri için farklı hiperparametreleri deneyin ve her denemede eğitim ve test sonuçlarını kaydedin.
   - `GridSearchCV` veya `RandomizedSearchCV` ile hiperparametre optimizasyonu yaparak en iyi parametreleri bulun.
2. **Sonuçları Karşılaştırma ve Yorumlama**
   - MLP ve RBF modellerinin sonuçlarını karşılaştırarak hangi modelin daha iyi performans gösterdiğini analiz edin.
   - Sonuçları tablo veya grafik olarak sunun ve performans farklılıklarının nedenlerini tartışın.

# 1. Gerekli Kütüphanelerin Yüklenmesi
"""

# Gerekli Kütüphanelerin Yüklenmesi

import numpy as np
import pandas as pd
import warnings
import time

# Veri ayırma ve performans metrikleri için
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.svm import SVC
from tqdm.notebook import tqdm
from sklearn.utils import resample


# Özellik ölçekleme için
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# Görselleştirme için
import matplotlib.pyplot as plt
import seaborn as sns

# PyTorch ve torchvision
import torch
import torchvision
from torchvision.datasets import GTSRB
import torchvision.transforms as transforms

# Uyarıları kapat
warnings.filterwarnings("ignore")

"""# 2. Veri Seti Yükleme ve Ön İşleme

## 2.1. Veri Setinin Yüklenmesi
"""

# 2. Veri Seti Yükleme ve Ön İşleme

# Dönüşümler (Transforms)
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

# Veri Setini Yükleme
train_dataset = GTSRB(root='.', split='train', transform=transform, download=True)
test_dataset = GTSRB(root='.', split='test', transform=transform, download=True)

# DataFrame'e dönüştürme
data_list = []

for img, label in train_dataset:
    data_list.append((img.numpy().flatten(), label))

# DataFrame oluştur
df = pd.DataFrame(data_list, columns=["image", "label"])

# Eksik değerleri kontrol et
print(df.isnull().sum())

# Eğer eksik değer varsa
if df.isnull().values.any():
    print("Eksik değerler mevcut!")
else:
    print("Eksik değer yok.")

# DataFrame'e dönüştürme
data_list2 = []

for img, label in test_dataset:
    data_list2.append((img.numpy().flatten(), label))

# DataFrame oluştur
df2 = pd.DataFrame(data_list2, columns=["image", "label"])

# Eksik değerleri kontrol et
print(df2.isnull().sum())

# Eğer eksik değer varsa
if df.isnull().values.any():
    print("Eksik değerler mevcut!")
else:
    print("Eksik değer yok.")

"""Veri setimizde eksik veri bulunmamaktadır.

## 2.2 Veri Ön İşleme
"""

# Eğitim ve test veri seti boyutlarını kontrol et
train_size = len(train_dataset)
test_size = len(test_dataset)

# Veri seti oranlarını hesapla
total_size = train_size + test_size
train_ratio = train_size / total_size
test_ratio = test_size / total_size

# Oranları yazdır
print(f"Eğitim veri seti boyutu: {train_size}")
print(f"Test veri seti boyutu: {test_size}")
print(f"Eğitim veri oranı: {train_ratio:.2f}")
print(f"Test veri oranı: {test_ratio:.2f}")

# Eğitim ve test veri setlerini birleştir
combined_df = pd.concat([df, df2], ignore_index=True)

# Veri setinin boyutunu kontrol et
print(f"Birleşik veri seti boyutu: {combined_df.shape}")

# Özellikler ve etiketleri ayırma
X = np.stack(combined_df['image'].values)  # Görüntü verileri
y = combined_df['label'].values            # Etiketler

# Veri setini %80 eğitim, %20 test olarak ayır
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Yeni veri seti boyutlarını kontrol et
print(f"Eğitim seti boyutu: {X_train.shape[0]}")
print(f"Test seti boyutu: {X_test.shape[0]}")

print(f"Eğitim seti oranı: {X_train.shape[0]/(X_train.shape[0]+X_test.shape[0])}")
print(f"Test seti oranı: {X_test.shape[0]/(X_train.shape[0]+X_test.shape[0])}")

# Standartlaştırıcıyı oluştur
scaler = StandardScaler()

# Eğitim verilerini dönüştür ve fit et
X_train_scaled = scaler.fit_transform(X_train)

# Test verilerini dönüştür
X_test_scaled = scaler.transform(X_test)

# Ölçeklendirilmiş veri setinin özelliklerini kontrol et
print("Eğitim verisi ortalama (yaklaşık 0 olmalı):", X_train_scaled.mean(axis=0))
print("Eğitim verisi standart sapma (yaklaşık 1 olmalı):", X_train_scaled.std(axis=0))

print("Test verisi ortalama (fit işleminden etkilenmez):", X_test_scaled.mean(axis=0))
print("Test verisi standart sapma (fit işleminden etkilenmez):", X_test_scaled.std(axis=0))

"""# 3. Model Eğitimi ve Hiperparametre Denemeleri

## 3.1. MLP Modeli:
- sklearn.neural_network.MLPClassifier kullanarak bir MLP modeli oluşturulması
"""

# MLP modeli oluşturma
mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=200, random_state=42, verbose=True)

# Modeli eğitim verisi üzerinde eğitme
mlp.fit(X_train_scaled, y_train)

# Modelin tahminlerini yapma
y_pred = mlp.predict(X_test_scaled)


# MLP modeli tanımlama
mlp_model = MLPClassifier(
    hidden_layer_sizes=(100,),  # 1 katman, 100 nöron
    activation='relu',          # Aktivasyon fonksiyonu
    solver='adam',              # Optimizasyon algoritması
    learning_rate='constant',   # Sabit öğrenme oranı
    random_state=42,
    max_iter=200,               # Maksimum iterasyon
    verbose=True
)

# Modeli eğitme
mlp_model.fit(X_train_scaled, y_train)

# Tahminleri alma
y_pred_train = mlp_model.predict(X_train_scaled)
y_pred_test = mlp_model.predict(X_test_scaled)

"""- Kurulan model için tahminleri değerlendirerek karışıklık matrisini (confusion_matrix) oluşturulması.
- Kurulan model için accuracy, precision, recall, ve F1-score gibi metriklernden gerekli olanları hesaplanması.
"""

# Karışıklık matrisi
conf_matrix = confusion_matrix(y_test, y_pred)

# Karışıklık matrisini görselleştirme
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

# Performans metriklerini yazdırma
print("\nEğitim doğruluk skoru:", accuracy_score(y_train, y_pred_train))
print("\nTest doğruluk skoru:", accuracy_score(y_test, y_pred_test))
print("\nPerformans raporu (test seti):")
print(classification_report(y_test, y_pred_test))

"""o	Hiperparametre denemeleri için farklı katman sayıları, nöron sayıları ve aktivasyon fonksiyonlarını test edilmesi"""

# Hiperparametre denemeleri için farklı konfigürasyonlar
param_grid = {
    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],
    'activation': ['relu', 'tanh'],
    'solver': ['adam', 'sgd'],
    'learning_rate': ['constant', 'adaptive']
}

# GridSearchCV ile en iyi hiperparametreleri bulma
from sklearn.model_selection import GridSearchCV

grid_search = GridSearchCV(MLPClassifier(max_iter=200, random_state=42), param_grid, cv=3, verbose=3)
grid_search.fit(X_train_scaled, y_train)

# En iyi hiperparametreleri yazdır
print("En iyi parametreler:", grid_search.best_params_)
print("En iyi skor:", grid_search.best_score_)

# En iyi model ile test verisinde değerlendirme
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test_scaled)

# Yeni karışıklık matrisi
conf_matrix_best = confusion_matrix(y_test, y_pred_best)

# Karışıklık matrisini görselleştirme
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix_best, annot=True, fmt='d', cmap='Reds', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.title("Confusion Matrix (Best Model)")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

# Performans metrikleri
print("Classification Report (Best Model):")
print(classification_report(y_test, y_pred_best))

# GridSearch sonuçlarını görselleştirme
results = pd.DataFrame(grid_search.cv_results_)
results = results.sort_values(by='mean_test_score', ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(x=results['param_hidden_layer_sizes'].astype(str), y=results['mean_test_score'], hue=results['param_activation'])
plt.title("Hiperparametre Performansı")
plt.xlabel("Hidden Layer Sizes")
plt.ylabel("Mean Test Score")
plt.xticks(rotation=45)
plt.legend(title="Activation Function")
plt.show()

"""Sonuçların görselleştirilmesi üzerine, relu fonksiyonunun tanh fonksiyonuna üstün geldiği görülmektedir.
Lakin gridcvsearch sonucunda en iyi parametreler:
- En iyi parametreler: {'activation': 'tanh', 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}
- En iyi skor: 0.9576967150496563
 şeklinde saptanmıştır.

## Performans Raporu: MLP Modeli Sonuçları

### 1. En İyi Hiperparametrelerin Seçimi
GridSearchCV sonucu, en iyi performansı aşağıdaki parametrelerle elde ettiğimizi gösteriyor:

- **Activation Function**: `tanh`
- **Hidden Layer Sizes**: `(100, 50)`
- **Learning Rate**: `constant`
- **Solver**: `sgd`

Bu parametre kombinasyonu ile **%95.77 doğruluk oranı** (`best_score_`) elde edilmiştir.

---

### 2. ReLU ve tanh Aktivasyon Fonksiyonlarının Karşılaştırması

#### ReLU
- Genellikle derin öğrenme modellerinde varsayılan olarak tercih edilen bir aktivasyon fonksiyonudur.
- **Avantajları**:
  - Pozitif değerlerde hızlı öğrenme sağlar.
  - Hesaplama maliyeti düşüktür.
  - Gradyan kaybı (vanishing gradient) sorununu azaltır.

#### tanh
- Çıkış değerlerini -1 ile 1 arasında sınırlar, bu da özellikle belirli bir ölçeğe bağlı olan veri dağılımlarında faydalı olabilir.
- Negatif ve pozitif değerleri simetrik olarak işlediği için bazen daha dengeli öğrenme sağlayabilir.

#### Neden tanh üstün geldi?
- GridSearchCV sırasında tanh, daha küçük bir "hidden_layer_sizes" ve "constant" öğrenme oranı ile kombinasyon halinde daha iyi performans göstermiştir.
- Bu durum:
  - Veri setinin tanh'nin sağladığı negatif simetriye daha uygun bir yapıda olabileceğini veya
  - Daha düşük nöron sayılarının aşırı öğrenmeyi önlediğini gösterebilir.

---

### 3. Sınıflar Arasında Performans Farklılıkları

- **Precision, Recall, F1-Score**: Genelde sınıflar arasında oldukça yüksek değerlere ulaşılmıştır, ancak bazı sınıflarda belirgin farklılıklar gözlenmektedir.
  - **Sınıf 24**:
    - `precision: 0.98`
    - `recall: 0.83`
    - `f1-score: 0.90`
    - Bu durum, Sınıf 24'e ait verilerin model tarafından hatalı tahmin edilme oranının daha yüksek olduğunu gösterir.
  - **Sınıf 32**:
    - `precision: 0.88`
    - `recall: 0.96`
    - `f1-score: 0.92`
    - Bu sınıfta daha düşük bir precision oranı gözlemlenmiştir. Model bu sınıfı tahmin ederken diğer sınıflarla karıştırmış olabilir.

#### Olası Sebepler:
- Bu sınıflara ait veri sayısı az olabilir, bu da modelin öğrenme kapasitesini etkileyebilir.
- Özellikle bu sınıflar arasında görsel veya özellik benzerlikleri varsa, model ayrıştırmakta zorlanabilir.

---

### 4. Dengeli ve Dengesiz Performans Alanları

#### Makro Ortalama (Macro Average)
- Precision, Recall ve F1-Score değerleri sırasıyla:
  - **Precision**: 0.97
  - **Recall**: 0.96
  - **F1-Score**: 0.96
- Bu metrikler, sınıf dengesizliği durumlarında model performansını ölçmek için idealdir ve modelin çoğu sınıfta dengeli performans sergilediğini gösterir.

#### Accuracy
- **%96.7** gibi yüksek bir doğruluk elde edilmiştir, ancak doğruluk dengesiz veri setlerinde yanıltıcı olabilir.
- Neyse ki, sınıflar arasında ciddi bir dengesizlik gözlemlenmemiştir.

---

### 5. Hiperparametrelerin Performansa Etkisi
GridSearchCV sonucunda görülen:
- Daha küçük bir gizli katman yapısı (`(100, 50)`) ve `sgd` gibi daha yavaş ancak kontrollü bir çözücü, modelin aşırı öğrenmeden kaçınmasına yardımcı olmuş olabilir.
- Aktivasyon fonksiyonu olarak `tanh`, sınıfların özelliklerini daha iyi yansıtmış olabilir.

---

### 6. Performansı İyileştirmek için Öneriler

#### Veri Dengesi ve Çeşitliliği
- Daha düşük recall veya precision değerine sahip sınıflar için veri artırma (data augmentation) teknikleri kullanılabilir.
- Örneğin:
  - Sınıf 24 ve Sınıf 32 için daha fazla örnek eklenmesi, bu sınıfların öğrenme sürecini iyileştirebilir.

#### Modelin Karmaşıklığını Artırma
- Daha fazla katman veya nöron eklemek, özellikle daha karmaşık veri yapılarını modellemek için faydalı olabilir.
- Ancak aşırı öğrenmeyi önlemek için dikkatli olunmalıdır.

#### Farklı Öğrenme Teknikleri Deneme
- `adam` veya `lbfgs` gibi alternatif optimizasyon algoritmalarını test etmek faydalı olabilir.
- Öğrenme oranı (`learning_rate`) adaptif hale getirilebilir (`adaptive`), böylece optimizasyon sırasında dinamik olarak ayarlanabilir.

#### Veri Ön İşleme Tekniklerini Geliştirme
- Özellik mühendisliği veya daha gelişmiş ölçekleme teknikleri (örneğin, PCA ile boyut indirgeme) denenebilir.

---

### 7. Sonuç ve Yorum
- Sonuçlar, modelin genel olarak başarılı bir şekilde öğrenme gerçekleştirdiğini ve **%96.7 doğruluk oranıyla çok iyi bir performans sergilediğini** göstermektedir.
- Ancak, belirli sınıflar arasındaki performans farklılıkları ve hiperparametre optimizasyonu ile daha yüksek performansa ulaşılabilir.
- Ayrıca, **relu** fonksiyonunun genelde daha hızlı öğrenmesi göz önünde bulundurularak, bu fonksiyon üzerinde daha fazla hiperparametre testi yapılabilir.

**Elde edilen sonuçlar, sınıflandırma problemi için oldukça tatmin edici olup, daha ileri iyileştirmelerle model daha da güçlendirilebilir.**

## 3.2. RBF Modeli

### 3.2.1 Veri Ön İşleme
"""

# 1. Dönüşümler (Transforms)
# Görselleri 32x32 boyutuna getir, tensöre çevir ve normalize et
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalizasyon eklendi
])

# 2. Veri Setini Yükleme
train_dataset = GTSRB(root='.', split='train', transform=transform, download=True)
test_dataset = GTSRB(root='.', split='test', transform=transform, download=True)

# 3. Veri Setlerini DataFrame'e Dönüştürme
def dataset_to_dataframe(dataset):
    data_list = []
    for img, label in dataset:
        # Görselleri düzleştirmeden tensor olarak saklıyoruz
        data_list.append((img.numpy(), label))
    df = pd.DataFrame(data_list, columns=["image", "label"])
    return df

train_df = dataset_to_dataframe(train_dataset)
test_df = dataset_to_dataframe(test_dataset)

# 4. Eksik Değer Kontrolü
for df_name, df in [("Eğitim Veri Seti", train_df), ("Test Veri Seti", test_df)]:
    print(f"{df_name} için eksik değer kontrolü:")
    print(df.isnull().sum())
    if df.isnull().values.any():
        print("Eksik değerler mevcut!")
    else:
        print("Eksik değer yok.")

# 5. Eğitim ve Test Veri Seti Boyutlarını Kontrol Etme
train_size = len(train_dataset)
test_size = len(test_dataset)
total_size = train_size + test_size
train_ratio = train_size / total_size
test_ratio = test_size / total_size
print(f"Eğitim veri seti boyutu: {train_size}")
print(f"Test veri seti boyutu: {test_size}")
print(f"Eğitim veri oranı: {train_ratio:.2f}")
print(f"Test veri oranı: {test_ratio:.2f}")

# 6. Eğitim ve Test Veri Setlerini %80 Eğitim - %20 Test Olarak Ayırma
combined_df = pd.concat([train_df, test_df], ignore_index=True)

# Özellikler ve etiketleri ayırma
X = np.stack(combined_df['image'].values)  # Görüntü verileri
y = combined_df['label'].values            # Etiketler

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Eğitim seti boyutu: {X_train.shape[0]}")
print(f"Test seti boyutu: {X_test.shape[0]}")

# 7. Pikselleri [0, 1] Aralığında Normalize Etme
X_train = X_train / 255.0
X_test = X_test / 255.0

# 8. Ekstra: Verilerin Normalizasyonunu Kontrol Etme
print("Eğitim verisi minimum ve maksimum değerleri:", X_train.min(), X_train.max())
print("Test verisi minimum ve maksimum değerleri:", X_test.min(), X_test.max())

# 9. Standartlaştırıcıyı Kullanma (Opsiyonel, görüntüler normalleştirildiği için gerekli olmayabilir)
scaler = StandardScaler()

# Eğer düzleştirilmiş verilere gerek varsa:
X_train_flat = X_train.reshape(X_train.shape[0], -1)
X_test_flat = X_test.reshape(X_test.shape[0], -1)

X_train_scaled = scaler.fit_transform(X_train_flat)
X_test_scaled = scaler.transform(X_test_flat)

print("Eğitim verisi ortalama (yaklaşık 0 olmalı):", X_train_scaled.mean(axis=0)[:5])  # İlk 5 özelliği kontrol
print("Eğitim verisi standart sapma (yaklaşık 1 olmalı):", X_train_scaled.std(axis=0)[:5])

"""### 3.2.2 RBF Modelinin Tanımlanması ve Eğitilmesi"""

# 1. RBF Modelini Tanımla
rbf_model = SVC(kernel='rbf', gamma='scale', random_state=42)

# 2. Modeli Eğit
print("Model eğitiliyor...")
rbf_model.fit(X_train_scaled, y_train)

"""### 3.2.3 RBF Base Modelinin Değerlendirilmesi"""

# 3. Test Veri Seti Üzerinde Tahmin Yap
y_pred = rbf_model.predict(X_test_scaled)

# 4. Performans Değerlendirme
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Doğruluk (Accuracy): {accuracy:.4f}")
print(f"Kesinlik (Precision): {precision:.4f}")
print(f"Hatırlama (Recall): {recall:.4f}")
print(f"F1 Skoru: {f1:.4f}")

# 5. Karışıklık Matrisi
conf_matrix = confusion_matrix(y_test, y_pred)

# 6. Karışıklık Matrisini Görselleştir
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Karışıklık Matrisi")
plt.xlabel("Tahmin Edilen Sınıf")
plt.ylabel("Gerçek Sınıf")
plt.show()

# Her sınıfın Precision, Recall ve F1 skorlarını hesaplamak faydalı olabilir. Bunun için classification_report kullanılması:

print(classification_report(y_test, y_pred))

"""### 3.2.4 Base Model Sonuçları ve Değerlendirme

#### Performans Metrikleri
- **Doğruluk (Accuracy):** 0.8822
- **Kesinlik (Precision):** 0.8976
- **Hatırlama (Recall):** 0.8822
- **F1 Skoru:** 0.8843

#### Genel Değerlendirme
Base model, veri setinin genelinde makul bir performans göstermiştir. Özellikle F1 skorunun yüksek olması, modelin sınıf dengesizliği durumunda dahi iyi çalıştığını göstermektedir. Ancak, bazı sınıflar için kesinlik (precision) ve hatırlama (recall) değerlerinde belirgin düşüşler görülmektedir. Bu durum, modelin bazı sınıfları ayırt etmekte zorlandığını işaret etmektedir.

#### Karışıklık Matrisi (Confusion Matrix)
Aşağıda, karışıklık matrisi sonuçlarına dayanarak yapılan gözlemler yer almaktadır:
1. **Hatalar:** Özellikle sınıf 4 ve sınıf 5 gibi bazı sınıflarda tahmin hatalarının arttığı gözlemlenmiştir. Model, bu sınıfları diğerleriyle karıştırma eğilimindedir.
2. **Başarılı Sınıflar:** Sınıf 1, 13, ve 38 gibi sınıflarda model oldukça yüksek doğrulukla tahmin yapmıştır.
3. **Dengesizlik Sorunları:** Bazı sınıflar için desteklenen örnek sayısının az olması, modelin bu sınıflarda düşük performans göstermesine neden olabilir.

#### Sınıf Bazlı Performans
Her sınıf için **precision**, **recall**, ve **f1-score** değerleri aşağıda özetlenmiştir:

| Sınıf | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0     | 1.00      | 0.76   | 0.86     | 42      |
| 1     | 0.89      | 0.91   | 0.90     | 444     |
| 2     | 0.86      | 0.87   | 0.86     | 450     |
| 3     | 0.80      | 0.77   | 0.78     | 282     |
| 4     | 0.56      | 0.91   | 0.70     | 396     |
| ...   | ...       | ...    | ...      | ...     |
| Toplam | 0.93      | 0.85   | 0.88     | 7854    |


#### Öneriler
1. **Hiperparametre Optimizasyonu:** Modelin performansını artırmak için `gamma` ve `C` gibi hiperparametrelerin optimize edilmesi gerekir.
2. **Daha İyi Veri Temsili:** Bazı sınıflar için yeterli sayıda veri olmayabilir. Veri artırma (data augmentation) yöntemleri uygulanabilir.
3. **Daha İleri Modeller:** Daha karmaşık RBF modelleri veya diğer makine öğrenimi algoritmaları (örneğin, derin öğrenme tabanlı yaklaşımlar) değerlendirilebilir.

---

Sonraki adımda, hiperparametre optimizasyonu kullanılarak en iyi model parametrelerini bulacağız.

### 3.2.5 RBF Modeli için Hiperparametre Optimizasyonu
"""

# Veri setini küçültmek için rastgele alt küme seçimi (ör. %10 veri)
subset_size = 0.1  # %10 veri
X_train_small, y_train_small = resample(
    X_train_scaled, y_train, n_samples=int(len(X_train_scaled) * subset_size), random_state=42
)

# Parametre aralığı
param_grid = {
    'C': [0.1, 1, 10],
    'gamma': [0.01, 0.1, 1],
    'kernel': ['rbf']
}

# GridSearchCV kullanımı
svc = SVC()
grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)

# Zaman ölçümünü başlat
start_time = time.time()

# Modeli eğit
print("Hiperparametre optimizasyonu başlıyor...")
grid_search.fit(X_train_small, y_train_small)

# Zaman ölçümünü bitir
end_time = time.time()
print(f"Hiperparametre optimizasyonu tamamlandı! Süre: {end_time - start_time:.2f} saniye")

# En iyi parametreler
best_params = grid_search.best_params_
print(f"En iyi parametreler: {best_params}")

# En iyi modelin performansını test veri setinde değerlendir
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test_scaled)

from sklearn.metrics import classification_report
print("En iyi modelin performans raporu:")
print(classification_report(y_test, y_pred_best))

import warnings
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.utils import resample
from sklearn.metrics import classification_report

# Uyarıları kapat
warnings.filterwarnings("ignore")

# Daha fazla veri kullanarak alt küme oluştur
subset_size = 0.2  # %20 veri
X_train_small, y_train_small = resample(
    X_train_scaled, y_train, n_samples=int(len(X_train_scaled) * subset_size), random_state=42
)

# Yeni parametre aralığı
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [0.001, 0.01, 0.1],
    'kernel': ['rbf']
}

# GridSearchCV kullanımı
svc = SVC()
grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)

# Hiperparametre optimizasyonu
print("Hiperparametre optimizasyonu başlıyor...")
grid_search.fit(X_train_small, y_train_small)
print("Hiperparametre optimizasyonu tamamlandı!")

# En iyi parametreler
best_params = grid_search.best_params_
print(f"En iyi parametreler: {best_params}")

# En iyi modelin performansını test veri setinde değerlendir
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test_scaled)

print("En iyi modelin performans raporu:")
print(classification_report(y_test, y_pred_best))

# Daha fazla veri kullanarak alt küme oluştur
subset_size = 0.5  # %50 veri
X_train_small, y_train_small = resample(
    X_train_scaled, y_train, n_samples=int(len(X_train_scaled) * subset_size), random_state=42
)

# Daha geniş ve optimize parametre aralığı
param_grid = {
    'C': [10, 50, 100, 500],
    'gamma': [0.001, 0.005, 0.01, 0.05],
    'kernel': ['rbf']
}

# GridSearchCV kullanımı
svc = SVC()
grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)

# Zaman ölçümünü başlat
start_time = time.time()
start_time_readable = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(start_time))

# Hiperparametre optimizasyonu
print(f"Hiperparametre optimizasyonu başlıyor... ({start_time_readable})")
grid_search.fit(X_train_small, y_train_small)

# Zaman ölçümünü bitir
end_time = time.time()
duration = end_time - start_time
end_time_readable = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(end_time))

print(f"Hiperparametre optimizasyonu tamamlandı! ({end_time_readable}) Süre: {duration:.2f} saniye")

# En iyi parametreler
best_params = grid_search.best_params_
print(f"En iyi parametreler: {best_params}")

# En iyi modelin performansını test veri setinde değerlendir
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test_scaled)

"""### 3.2.6 RBF Optimize edilmiş Modelin Değerlendirilmesi"""

# Karışıklık matrisini hesapla
conf_matrix = confusion_matrix(y_test, y_pred_best)

# Karışıklık matrisini görselleştir
plt.figure(figsize=(12, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Optimize Edilmiş Model: Karışıklık Matrisi")
plt.xlabel("Tahmin Edilen Sınıf")
plt.ylabel("Gerçek Sınıf")
plt.show()

# Performans metriklerini hesapla
accuracy = accuracy_score(y_test, y_pred_best)
precision = precision_score(y_test, y_pred_best, average='weighted')
recall = recall_score(y_test, y_pred_best, average='weighted')
f1 = f1_score(y_test, y_pred_best, average='weighted')

# Performans metriklerini yazdır
print(f"Doğruluk (Accuracy): {accuracy:.4f}")
print(f"Kesinlik (Precision): {precision:.4f}")
print(f"Hatırlama (Recall): {recall:.4f}")
print(f"F1 Skoru: {f1:.4f}")

# Sınıf bazlı performans raporu
print("En iyi modelin performans raporu:")
print(classification_report(y_test, y_pred_best))

"""## Optimize Edilmiş Model Performans Raporu ve Farklılıkların Tartışılması

### 1. Performans Metriklerinin Karşılaştırılması

| Metrik         | Base Model | Optimize Edilmiş Model |
|----------------|------------|-------------------------|
| **Accuracy**   | 0.8822     | 0.9176                 |
| **Precision**  | 0.8976     | 0.9228                 |
| **Recall**     | 0.8822     | 0.9176                 |
| **F1-Score**   | 0.8843     | 0.9178                 |

- Optimize edilmiş model, tüm performans metriklerinde base modele göre belirgin bir iyileşme sağlamıştır.

### 2. Farklılıkların Nedenleri

#### A. Hiperparametre Optimizasyonu
- **Base Model:** Varsayılan parametrelerle çalıştığından, modelin karmaşıklığı ve genelleme kapasitesi sınırlıydı.
- **Optimize Edilmiş Model:** `C=100` ve `gamma=0.001` değerleri, modelin karar sınırlarını daha esnek ve hassas hale getirmiştir.
  - **C (Regularization):** Daha yüksek bir değer, daha düşük bias ve daha iyi sınıf ayrımı sağlamıştır.
  - **Gamma:** Daha düşük bir `gamma`, karar sınırlarını daha pürüzsüz hale getirerek overfitting riskini azaltmıştır.

#### B. Daha Geniş Veri Kullanımı
- Optimize edilmiş modelin eğitimi sırasında daha geniş bir veri kümesi (%50) kullanıldı.
- Bu, modelin daha fazla örneği öğrenmesine olanak tanımış ve sınıf çeşitliliği ile genelleme kapasitesini artırmıştır.

#### C. Sınıf Dengesizliği ile Mücadele
- Optimize edilmiş model, sınıflar arasındaki dengesizliklere daha iyi adapte olmuştur.
- Bu, özellikle düşük destekli sınıflarda (ör. sınıf 0 ve sınıf 42) performansın artmasına neden olmuştur.

### 3. Karışıklık Matrisi Analizi
- **Yanlış Pozitiflerin Azalması:** Sınıf 1, 2, 4 ve 5 gibi yaygın sınıflar için yanlış pozitifler önemli ölçüde azalmıştır.
- **Yanlış Negatiflerin Azalması:** Sınıf 17 ve 38 gibi yüksek destekli sınıflarda model, doğru tahmin oranını artırmıştır.
- **Karışıklıkta Düşüş:** Sınıf 23 ve 24 gibi düşük destekli sınıflarda diğer sınıflarla karışıklık azalmış, model bu sınıfları daha doğru şekilde tahmin etmiştir.

### 4. İyileşmenin Sınırlı Olduğu Alanlar
- **Sınıf 0:** Model, sınıf 0 için hala %100 doğruluk sağlayamamıştır. Bunun nedeni, sınıf 0’ın düşük destekli olması ve diğer sınıflarla olan benzerlikler olabilir.
- **Sınıf 15:** Sınıf 15’te precision (%99) yüksek olsa da recall (%77) daha düşüktür. Bu durum, modelin bu sınıfı yeterince iyi öğrenemediğini gösterebilir.
- **Sınıf 41 ve 42:** Düşük destekli bu sınıflar için F1-skoru (%91 ve %91) yüksek olsa da, hala sınırlı iyileştirmeler gözlemlenmiştir.

### 5. Performans Artışı Sağlayan Faktörler
- **Hiperparametre Optimizasyonu:** `C` ve `gamma` değerlerinin hassas bir şekilde ayarlanması, modelin karar sınırlarının doğruluğunu artırmıştır.
- **Daha Fazla Veri Kullanımı:** Daha büyük bir veri alt kümesi ile eğitim yapılması, modelin öğrenme kapasitesini artırmış ve daha iyi genelleme sağlamıştır.
- **Kernel Fonksiyonu:** RBF kernel fonksiyonunun kullanımı, lineer olmayan veri yapılarında daha doğru karar sınırları oluşturulmasına olanak tanımıştır.

### 6. Sonuç ve Öneriler

#### Sonuç
- Optimize edilmiş model, sınıf bazlı performansta önemli iyileştirmeler sağlamıştır. Ancak bazı düşük destekli sınıflar için performans hala optimize edilebilir.

#### Öneriler
- **Daha Fazla Veri ile Eğitim:** Özellikle düşük destekli sınıflar için veri artırma teknikleri (data augmentation) kullanılabilir.
- **Farklı Kernel Fonksiyonları:** Özellikle sınıf 0 gibi zor sınıflar için farklı kernel fonksiyonları (ör. polynomial kernel) denenebilir.
- **Hiperparametrelerin İncelenmesi:** `C` ve `gamma` değerleri daha hassas bir aralıkta optimize edilebilir.
- **Modelin Zenginleştirilmesi:** Özellikle derin öğrenme tabanlı modellerle karşılaştırma yapılabilir.

Bu sonuçlar doğrultusunda, modelin performansını daha da iyileştirmek için önerilen stratejiler uygulanabilir.
"""